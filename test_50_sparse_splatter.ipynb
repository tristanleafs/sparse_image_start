{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is the same basic setup for a CNN pipeline but with with sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=False,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code for viewing images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ds_train.take(1)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "for sample in example:\n",
    "    image, label = sample[0].numpy(), sample[1].numpy()\n",
    "    plt.imshow(image[:, :, 0].astype(np.uint8), cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.show()\n",
    "    print(\"Label: %d\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 8), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 1, 0, 0]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform((6,8), maxval=2,dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code for making images sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_sparse(image, label, sparicty=.5):\n",
    "    ones = np.ones(shape=image.shape)\n",
    "    indices = np.random.choice(np.arange(ones.shape[0]*ones.shape[1]*ones.shape[2]), replace=False,\n",
    "                           size=int(ones.shape[0]*ones.shape[1]*ones.shape[2] * sparicty))\n",
    "\n",
    "    # sparse = tf.random.uniform(shape=image.shape, minval=0, maxval=2,dtype='int32')\n",
    "    # sparse = tf.cast(sparse, tf.float32)\n",
    "    ones[np.unravel_index(indices, ones.shape)] = 0\n",
    "    sparse = tf.constant(ones, dtype=tf.float32)\n",
    "    new_image = image * sparse\n",
    "    return new_image, label\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(make_image_sparse, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test image manipulation\n",
    "\n",
    "**Note:** I do not make the validation data sparse because it allows for better performance. This performance difference is likely due to having sparse training data but not sparse testing data has a similar effect on the model has having dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# ds_test = ds_test.map(make_image_sparse, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viewing sparse training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "example_sparse = ds_train.take(1)\n",
    "for sample in example_sparse:\n",
    "    image, label = sample[0].numpy()*255, sample[1].numpy()\n",
    "    plt.imshow(image[:, :, 0].astype(np.uint8), cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.show()\n",
    "    print(\"Label: %d\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viewing non-sparse test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    }
   ],
   "source": [
    "example_test = ds_test.take(1)\n",
    "for sample in example_test:\n",
    "    image, label = sample[0].numpy()*255, sample[1].numpy()\n",
    "    plt.imshow(image[:, :, 0].astype(np.uint8), cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.show()\n",
    "    print(\"Label: %d\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regular steps follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ds_train = ds_train.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# ds_train = ds_train.cache()\n",
    "# ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "# ds_train = ds_train.batch(128)\n",
    "# ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test = ds_test.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# ds_test = ds_test.batch(128)\n",
    "# ds_test = ds_test.cache()\n",
    "# ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_layers import splatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = splatter(10, 3, input_shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\nEncountered error:\n\"\"\"\nin user code:\n\n    c:\\Users\\trist\\Documents\\Dev\\Sparse\\custom_layers.py:97 call  *\n        return call_splat_conv2d(input, self.kernel)\n    c:\\Users\\trist\\Documents\\Dev\\Sparse\\custom_layers.py:12 call_splat_conv2d  *\n        for ind, channel in enumerate(image):\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\py_builtins.py:388 enumerate_  **\n        return _py_enumerate(s, start)\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\py_builtins.py:396 _py_enumerate\n        return enumerate(s, start)\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:503 __iter__\n        self._disallow_iteration()\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:477 _disallow_in_graph_mode\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n\n\"\"\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    c:\\Users\\trist\\Documents\\Dev\\Sparse\\custom_layers.py:97 call  *\n        return call_splat_conv2d(input, self.kernel)\n    c:\\Users\\trist\\Documents\\Dev\\Sparse\\custom_layers.py:12 call_splat_conv2d  *\n        for ind, channel in enumerate(image):\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\py_builtins.py:388 enumerate_  **\n        return _py_enumerate(s, start)\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\py_builtins.py:396 _py_enumerate\n        return enumerate(s, start)\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:503 __iter__\n        self._disallow_iteration()\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:477 _disallow_in_graph_mode\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26168/497126169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = tf.keras.models.Sequential([\n\u001b[0m\u001b[0;32m      2\u001b[0m   splatter(\n\u001b[0;32m      3\u001b[0m     \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    204\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m             raise TypeError('You are attempting to use Python control '\n\u001b[0m\u001b[0;32m   1121\u001b[0m                             \u001b[1;34m'flow in a layer that was not declared to be '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m                             \u001b[1;34m'dynamic. Pass `dynamic=True` to the class '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\nEncountered error:\n\"\"\"\nin user code:\n\n    c:\\Users\\trist\\Documents\\Dev\\Sparse\\custom_layers.py:97 call  *\n        return call_splat_conv2d(input, self.kernel)\n    c:\\Users\\trist\\Documents\\Dev\\Sparse\\custom_layers.py:12 call_splat_conv2d  *\n        for ind, channel in enumerate(image):\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\py_builtins.py:388 enumerate_  **\n        return _py_enumerate(s, start)\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\py_builtins.py:396 _py_enumerate\n        return enumerate(s, start)\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:503 __iter__\n        self._disallow_iteration()\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    C:\\Users\\trist\\anaconda3\\envs\\venv_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:477 _disallow_in_graph_mode\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n\n\"\"\""
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  splatter(\n",
    "    filters=10,\n",
    "    kernel_size=3,\n",
    "    \n",
    "    \n",
    "    input_shape=( 28, 28, 1),\n",
    "    \n",
    "    ),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=5,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(ds_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b861f79aa0cc4f016d3000add6b29d14e2b02b65ebc1e18d56aaf109b4022744"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv_tens': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
